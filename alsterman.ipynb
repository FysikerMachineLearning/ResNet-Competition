{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-Competition\n",
    "\n",
    "__Author:Marcus Alsterman<br>\n",
    "Name here [marals@kth.se](mailto:marals@kth.se)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "# load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_test = X_train/255, X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # seeding\n",
    "# seed = 95\n",
    "# np.random.seed(seed)\n",
    "# rn.seed(seed + 1)\n",
    "# session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "#                               inter_op_parallelism_threads=1)\n",
    "# from keras import backend as K\n",
    "# tf.set_random_seed(seed + 2)\n",
    "# sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense, ReLU, Add, Flatten\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.utils import to_categorical\n",
    "ES = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=0, mode='auto', baseline=None, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_count =  355\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADKCAYAAAC11LviAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAEsNJREFUeJzt3V2MXGd9x/Hfb2d3vbu245cEp1aSNhRxQVQVI1kRUnoRoEKBoiZIpSJqUSohmYsiBYmqpNxAkZBSiZdWAiG5JCJIvDQqpESoKlhpqpSbFDukJJGpoChAsBWTOrbXXu/LzP57MSfqNjx/77ztrPfZ70eydubv4zPPmd39z/GZ3zyPI0IAgK1vYrMHAAAYDRo6AFSChg4AlaChA0AlaOgAUAkaOgBUgoYOAJWgoQNAJWjoAFCJyWH+se07JP2dpJakL0bE/etsz8dSAaB/L0XEa9bbaOAzdNstSZ+X9A5Jt0i62/Ytg+4PAJD6WS8bDXPJ5VZJP4mIn0bEsqSvS7pziP0BAIYwTEO/QdIv1tx/oan9P7aP2D5u+/gQjwUAWMcw19BdqP3aNfKIOCrpqMQ1dADYSMOcob8g6aY192+UdGq44QAABjVMQ/++pNfbfq3taUnvlfToaIYFAOjXwJdcIqJt+4OSvqNubPHBiHhuZCMDAPTF41yxiGvoADCQExFxeL2N+KQoAFSChg4AlaChA0AlhprLBYMqRfivsLXL22f1Uen3/ZV8e946AcaBM3QAqAQNHQAqQUMHgErQ0AGgEjR0AKgEKZe+9Jc2yeoTE62kXn59tcv1fveTWV1dTeqdEdXL+ycVs/30m5za6CRXbThDB4BK0NABoBI0dACoBA0dACpBQweASmzzlEu/6ZTy699ka6pcn5ou1qemZor1HTtmk/pcsT49Xd6+1SqnX7KEQbu9XKwvLS0k9cvF+uLipWJ9ZXmx/LidlWI9T8WU6+jfONdBGMZGj7O2FA1n6ABQCRo6AFSChg4AlaChA0AlaOgAUImhUi62n5c0L6kjqd3LqtSbo8/UymQ5tTI1taNYz1Ios7O7ivWdO/cW67t370/q1xbrc3O7i/XJyXK6JksMLCXplPmLLxfr58//qrz9/Nli/dKlc8V6mopZWSrWO512sZ7NIbOdbJXUytUme962avplFLHFt0TESyPYDwBgCFxyAYBKDNvQQ9J3bZ+wfaS0ge0jto/bPj7kYwEArmDYSy63RcQp2wckHbP9o4h4Yu0GEXFU0lFJss2FPgDYIEOdoUfEqebrGUmPSLp1FIMCAPRv4DN02zslTUTEfHP77ZI+MbKRDTaqYrXfNEs2R8rsTJJa2VVOrVxzTTmdsnfvgWJ9z56kfm15/zv37CzWp3aUjyubI2XxYnlulgsvlVM3MzPJ4yZz1/SbGMiSB1k9O64aVz4izTIeWzX9Mswll+slPdIc4KSkr0bEv4xkVACAvg3c0CPip5LeOMKxAACGQGwRACpBQweAStDQAaASVa1YlK80VF7BJ5vzJFs5aG7nNcX6nj3XFev79h0s1vfv/41ife+BPcX6zj3ldM2OufLcMhMT5edhdbX8zv3UdPJjkDyf2X6ylY+WkxWLsno+l0t5haPs+04iBKN2tadfOEMHgErQ0AGgEjR0AKgEDR0AKkFDB4BKbNGUS/kd5eyd5laWcmn1N5fL3Fw55bJr175iPZvLZde+cmpleqacusnmKrmczMHS7zvx2fatyfLzlo1zenqmWM9Wemq1yvt38v3dTkjoYBCcoQNAJWjoAFAJGjoAVIKGDgCVoKEDQCW2aMqlLJ1PIZvjpVU+/GyOlyzFMTtbTq3MzJXTMq1W+XV0aaE8h8ny4nyxvrLcLtYz2ZwtWWolk68QVNZvYiOSlYayxyURAnRxhg4AlaChA0AlaOgAUAkaOgBUYt2GbvtB22dsP7umtt/2Mds/br6WP/sOABibXlIuX5L0OUlfXlO7T9JjEXG/7fua+x8Z/fA2Vjr3S5/pl8nJ8lwl2f6XLpfTLIuXyvWFhXLKJVvBJxtnlsbJeKL8et9O0jXtlfKKRZ12eZydTqdYX10t1yP6S9cA2826Z+gR8YSks68q3ynpoeb2Q5LuGvG4AAB9GvQa+vURcVqSmq8HRjckAMAgNvyDRbaPSDqy0Y8DANvdoGfoL9o+KEnN1zPZhhFxNCIOR8ThAR8LANCDQRv6o5LuaW7fI+lboxkOAGBQ615ysf01SbdLus72C5I+Jul+SQ/bfr+kn0t6z0YOslf9zunR7wpHU2nKpfw0ZuPJ5my5dOl8sb64eKlYz9I42QpBE5Pl1++JZGWi1U45VbKSpFmWlheL9eWV8vF2OuW0TP9zszCXC8YjnS/qKrFuQ4+Iu5O/etuIxwIAGAKfFAWAStDQAaASNHQAqAQNHQAqsUVXLBpNqiF7xzpdyShLj0z0l3Jpt5N0R7IiT7ZS0sxMeW6WXXt2F+uzu8srKE1NTxXrC/MLxXq7XU65LC9fLtazOWeYmwUYLc7QAaASNHQAqAQNHQAqQUMHgErQ0AGgEls05VKWpUrsZA6TJJ0yOVlOfWRzvEwk9X7nJJnekaRZ5nYW67v3llMuO5P61I7yca0mKwctXirPzZLNwbK62t/cLFY5ZZSlj7LvIzAueY+5OuZ44TcEACpBQweAStDQAaASNHQAqAQNHQAqUVXKJZ2bZaL8upWt+JOlVpzUV1fLKZHoZOma8n6mZ8pzxey5bk+xvnt/MmfLrvKcLZ0kzbKUpFlWk7llsjlYnJwfZM+/SLMAI8VvDgBUgoYOAJWgoQNAJWjoAFCJdRu67Qdtn7H97Jrax23/0vbTzZ93buwwAQDr6SXl8iVJn5P05VfVPxsRnxr5iDZAlipptZI0S5KyyOYqyVbkyVI3Wbpmema6WN8xV06/TM+U52ZJV0paLo9/abG8AtHKYn8rDTlJs+Rz6YzqP4jZPBqjWdlqI/U73w9wJev+RkXEE5LOjmEsAIAhDHOK9EHbP2wuyewb2YgAAAMZtKF/QdLrJB2SdFrSp7MNbR+xfdz28QEfCwDQg4EaekS8GBGd6F5M/XtJt15h26MRcTgiDg86SADA+gZq6LYPrrn7bknPZtsCAMZj3ZSL7a9Jul3SdbZfkPQxSbfbPqRujOB5SR/YwDH2LJ3LJUlZZCvmZCmOlZVyGmRpaaFYz+ZCmZwsp1mmV8r15SSFcvliltIplrW8VE6tLM5fLtZXlsqP2++qLVnKhYQHMFrrNvSIuLtQfmADxgIAGAKfFAWAStDQAaASNHQAqAQNHQAqUdmKRUmaJV0xJ0lfJOmUlZWlYn1xsZxyabfLc6dMT8+Ux5PwRDk90mmXVyDK5khZTVYsylI0nU75eehXZCs6JSmXbAUoYLNlSa6rBWfoAFAJGjoAVIKGDgCVoKEDQCVo6ABQiS2acknmbEnSHdmKRf2umJOlLzqdcpqllTxuu11OlWTjXL5cnuOlNVnePl3JaDWZOyWdgyWb6yZJpyQpmk7yvGUrQGX7z+bYAdDFGToAVIKGDgCVoKEDQCVo6ABQCRo6AFRiS6Zc0pVxkvRLvpJOkpZplZ+WyclyemRqqpxCmZreUay3WuX9ZHO8TO1IVjhK0izZ9tkKSu1kTpgsbdJpl1c+Wl5ZLO8/mQOnnewnSxOxwhFwZZyhA0AlaOgAUAkaOgBUgoYOAJVYt6Hbvsn247ZP2n7O9r1Nfb/tY7Z/3Hzdt/HDBQBkekm5tCV9OCKesr1b0gnbxyT9maTHIuJ+2/dJuk/SRzZuqIPL0hHZCketVjJHyvRssT4zsyup7yzWd8yW0ywzO8v12V3lx90xW07RZCscLS2U0yarScplaam8EtPC5flifXHxUnk/y0n6JZnTpv+UC+kXQOrhDD0iTkfEU83teUknJd0g6U5JDzWbPSTpro0aJABgfX1dQ7d9s6Q3SXpS0vURcVrqNn1JB0Y9OABA73r+YJHtXZK+IelDEXGh18VSbR+RdGSw4QEAetXTGbrtKXWb+Vci4ptN+UXbB5u/PyjpTOnfRsTRiDgcEYdHMWAAQFkvKRdLekDSyYj4zJq/elTSPc3teyR9a/TDAwD0qpdLLrdJep+kZ2w/3dQ+Kul+SQ/bfr+kn0t6z8YM8delK+YkK9pkc49kc4x0kpV3sstM08mcLXO7yimXuWvKqZXZ3XPl/c+U52aZaJVfj5cvl9MjWcrlwssXivVz54r/6dKFCy8V65cunS8/bpJ+aa+MKuUCjFavl5SvNus29Ij4nrI136S3jXY4AIBB8UlRAKgEDR0AKkFDB4BK0NABoBJbcsWiTKfTLtaXkzTLYjJXyeWFcupjdrY8Z8vs7O5iPVshSH2+g95eLh9Xu12uX3z5YrF+7szZYv2l//llsX727Kli/fz5csplIUu5LF8u1tudbMWi5HmrcM6WLE1Bomc8tmqaJcMZOgBUgoYOAJWgoQNAJWjoAFAJGjoAVGKLplySuVySdES2Ms5CkmZxOtNBWTb3SCdJcSwvXlusZysQZYmHxYVyemR+vpxmSedmOf+rcj3Zz+JiOUWzvDSaNEskc/JsJ6RfRqu2NEuGM3QAqAQNHQAqQUMHgErQ0AGgEjR0AKjEFk25ZMoJgHayYlGWpsjmhFlK5n65eOlcsX727OlifWamvJJRqzVVrGdWVhaL9cVkhaCsvpSkU5azOViS1FD+PJe/L6RZ+kf6pWu7pFb6xRk6AFSChg4AlaChA0AlaOgAUIl1G7rtm2w/bvuk7eds39vUP277l7afbv68c+OHCwDIeL13x20flHQwIp6yvVvSCUl3SfpjSRcj4lM9P5h9lb0VX36nfGKi/DrXapVDQRMTrWJ9crKcWmlNlPfj5HH7TYnkc8uU66ur5VRPNtdKtv/ttNLQVne1pWJIrazrREQcXm+jdWOLEXFa0unm9rztk5JuGH58AIBR6usauu2bJb1J0pNN6YO2f2j7Qdv7Rjw2AEAfem7otndJ+oakD0XEBUlfkPQ6SYfUPYP/dPLvjtg+bvv4CMYLAEisew1dkmxPSfq2pO9ExGcKf3+zpG9HxO+ss5+r68Id19Cb7bmGvt1wDX3L6ekaei8pF0t6QNLJtc28ebP0Fe+W9OwgowQAjEYvc7ncJul9kp6x/XRT+6iku20fUvf063lJH9iQEW6o/lY+iijPVWKXz3CzOU+yM/p+9Xvmnm/fX/0KI+pze2wWzojr1EvK5XsqX5v459EPBwAwKD4pCgCVoKEDQCVo6ABQCRo6AFSishWLRqXfNEh/e89WRAKAYXCGDgCVoKEDQCVo6ABQCRo6AFSChg4AlRh3yuUlST9rbl/X3N8uON56badjlTjezfBbvWzU0/S5G8H28V6mg6wFx1uv7XSsEsd7NeOSCwBUgoYOAJXYzIZ+dBMfezNwvPXaTscqcbxXrU27hg4AGC0uuQBAJcbe0G3fYfu/bP/E9n3jfvxxsP2g7TO2n11T22/7mO0fN1/3beYYR8X2TbYft33S9nO2723qtR7vjO3/sP2fzfH+dVN/re0nm+P9B9vTmz3WUbHdsv0D299u7td8rM/bfsb207aPN7Ut87M81oZuuyXp85LeIekWddclvWWcYxiTL0m641W1+yQ9FhGvl/RYc78GbUkfjog3SHqzpD9vvqe1Hu+SpLdGxBslHZJ0h+03S/obSZ9tjvdlSe/fxDGO2r2STq65X/OxStJbIuLQmqjilvlZHvcZ+q2SfhIRP42IZUlfl3TnmMew4SLiCUlnX1W+U9JDze2HJN011kFtkIg4HRFPNbfn1f3Fv0H1Hm9ExMXm7lTzJyS9VdI/NvVqjtf2jZL+QNIXm/tWpcd6BVvmZ3ncDf0GSb9Yc/+FprYdXB8Rp6VuE5R0YJPHM3K2b5b0JklPquLjbS5BPC3pjKRjkv5b0rmIeGWi+5p+rv9W0l9KWm3uX6t6j1Xqvjh/1/YJ20ea2pb5WR73R/9dqBGzqYDtXZK+IelDEXGheyJXp4joSDpke6+kRyS9obTZeEc1erbfJelMRJywffsr5cKmW/5Y17gtIk7ZPiDpmO0fbfaA+jHuM/QXJN205v6Nkk6NeQyb5UXbByWp+Xpmk8czMran1G3mX4mIbzblao/3FRFxTtK/qfvewV7br5wg1fJzfZukP7T9vLqXR9+q7hl7jccqSYqIU83XM+q+WN+qLfSzPO6G/n1Jr2/eJZ+W9F5Jj455DJvlUUn3NLfvkfStTRzLyDTXVB+QdDIiPrPmr2o93tc0Z+ayPSvp99V93+BxSX/UbFbF8UbEX0XEjRFxs7q/q/8aEX+iCo9VkmzvtL37lduS3i7pWW2hn+Wxf7DI9jvVfZVvSXowIj451gGMge2vSbpd3VnaXpT0MUn/JOlhSb8p6eeS3hMRr37jdMux/XuS/l3SM/q/66wfVfc6eo3H+7vqvjHWUveE6OGI+ITt31b3LHa/pB9I+tOIWNq8kY5Wc8nlLyLiXbUea3NcjzR3JyV9NSI+aftabZGfZT4pCgCV4JOiAFAJGjoAVIKGDgCVoKEDQCVo6ABQCRo6AFSChg4AlaChA0Al/hdHCv+ICcpLXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data preprocessing\n",
    "cutoff = 0.051\n",
    "mean_train_image = np.mean(X_train, axis=0)\n",
    "mean_train_image_cutoff = mean_train_image > cutoff\n",
    "plt.imshow(np.concatenate((mean_train_image ,mean_train_image_cutoff), axis=1), clim=[0,1], cmap='bone')\n",
    "\n",
    "pixel_count = np.sum(mean_train_image_cutoff)\n",
    "print('pixel_count = ',pixel_count)\n",
    "\n",
    "X_train = X_train[:, mean_train_image_cutoff]\n",
    "X_test = X_test[:, mean_train_image_cutoff]\n",
    "\n",
    "# one hot\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = Input(shape=(pixel_count,))\n",
    "x = x_in\n",
    "num_layers = 5\n",
    "for i in range(0,num_layers):\n",
    "    x = Dense(20, activation='relu')(x)\n",
    "x = Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[x_in], outputs= x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 355)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                7120      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 9,010\n",
      "Trainable params: 9,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='AdaGrad',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 5s 84us/step - loss: 0.5081 - acc: 0.8452 - val_loss: 0.2892 - val_acc: 0.9178\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 0.3193 - acc: 0.9089 - val_loss: 0.2414 - val_acc: 0.9290\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 0.2799 - acc: 0.9209 - val_loss: 0.2164 - val_acc: 0.9355\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 0.2554 - acc: 0.9277 - val_loss: 0.1981 - val_acc: 0.9427\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 4s 69us/step - loss: 0.2371 - acc: 0.9322 - val_loss: 0.1855 - val_acc: 0.9475\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 4s 69us/step - loss: 0.2235 - acc: 0.9366 - val_loss: 0.1781 - val_acc: 0.9493\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 0.2129 - acc: 0.9397 - val_loss: 0.1709 - val_acc: 0.9510\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 4s 69us/step - loss: 0.2043 - acc: 0.9422 - val_loss: 0.1655 - val_acc: 0.9537\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 4s 71us/step - loss: 0.1973 - acc: 0.9428 - val_loss: 0.1633 - val_acc: 0.9555\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 4s 71us/step - loss: 0.1912 - acc: 0.9453 - val_loss: 0.1580 - val_acc: 0.9580\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 0.1863 - acc: 0.9468 - val_loss: 0.1554 - val_acc: 0.9578\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 4s 69us/step - loss: 0.1813 - acc: 0.9476 - val_loss: 0.1546 - val_acc: 0.9570\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 0.1773 - acc: 0.9492 - val_loss: 0.1502 - val_acc: 0.9613\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 4s 69us/step - loss: 0.1738 - acc: 0.9506 - val_loss: 0.1506 - val_acc: 0.9588\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 4s 69us/step - loss: 0.1703 - acc: 0.9508 - val_loss: 0.1469 - val_acc: 0.9608\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 0.1671 - acc: 0.9514 - val_loss: 0.1455 - val_acc: 0.9628\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 0.1645 - acc: 0.9526 - val_loss: 0.1467 - val_acc: 0.9617\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 0.1621 - acc: 0.9531 - val_loss: 0.1439 - val_acc: 0.9622\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 4s 69us/step - loss: 0.1596 - acc: 0.9541 - val_loss: 0.1411 - val_acc: 0.9638\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 0.1575 - acc: 0.9548 - val_loss: 0.1416 - val_acc: 0.9638\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 4s 69us/step - loss: 0.1553 - acc: 0.9552 - val_loss: 0.1397 - val_acc: 0.9635\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 0.1535 - acc: 0.9556 - val_loss: 0.1405 - val_acc: 0.9633\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 0.1515 - acc: 0.9560 - val_loss: 0.1390 - val_acc: 0.9632\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 44s 814us/step - loss: 0.1499 - acc: 0.9561 - val_loss: 0.1380 - val_acc: 0.9632\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 0.1484 - acc: 0.9570 - val_loss: 0.1372 - val_acc: 0.9647\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.1466 - acc: 0.9576 - val_loss: 0.1373 - val_acc: 0.9655\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 5s 98us/step - loss: 0.1453 - acc: 0.9579 - val_loss: 0.1357 - val_acc: 0.9648\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.1438 - acc: 0.9584 - val_loss: 0.1380 - val_acc: 0.9637\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.1425 - acc: 0.9582 - val_loss: 0.1356 - val_acc: 0.9652\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 4s 78us/step - loss: 0.1413 - acc: 0.9594 - val_loss: 0.1358 - val_acc: 0.9642\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.1402 - acc: 0.9593 - val_loss: 0.1360 - val_acc: 0.9655\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 4s 78us/step - loss: 0.1390 - acc: 0.9596 - val_loss: 0.1350 - val_acc: 0.9653\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 4s 81us/step - loss: 0.1378 - acc: 0.9597 - val_loss: 0.1343 - val_acc: 0.9648\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 4s 79us/step - loss: 0.1368 - acc: 0.9602 - val_loss: 0.1344 - val_acc: 0.9643\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.1358 - acc: 0.9609 - val_loss: 0.1321 - val_acc: 0.9652\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 71s 1ms/step - loss: 0.1348 - acc: 0.9607 - val_loss: 0.1330 - val_acc: 0.9643\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 4s 69us/step - loss: 0.1339 - acc: 0.9609 - val_loss: 0.1347 - val_acc: 0.9640\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 5s 96us/step - loss: 0.1330 - acc: 0.9610 - val_loss: 0.1322 - val_acc: 0.9658\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 5s 94us/step - loss: 0.1323 - acc: 0.9618 - val_loss: 0.1317 - val_acc: 0.9657\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 4s 82us/step - loss: 0.1313 - acc: 0.9617 - val_loss: 0.1330 - val_acc: 0.9655\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 4s 79us/step - loss: 0.1306 - acc: 0.9620 - val_loss: 0.1320 - val_acc: 0.9653\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.1295 - acc: 0.9620 - val_loss: 0.1311 - val_acc: 0.9657\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 4s 79us/step - loss: 0.1289 - acc: 0.9621 - val_loss: 0.1320 - val_acc: 0.9652\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 4s 79us/step - loss: 0.1283 - acc: 0.9628 - val_loss: 0.1338 - val_acc: 0.9647 loss:\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.1276 - acc: 0.9629 - val_loss: 0.1323 - val_acc: 0.9657\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 4s 79us/step - loss: 0.1268 - acc: 0.9631 - val_loss: 0.1330 - val_acc: 0.9643\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 4s 80us/step - loss: 0.1261 - acc: 0.9631 - val_loss: 0.1351 - val_acc: 0.9640\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 71s 1ms/step - loss: 0.1253 - acc: 0.9634 - val_loss: 0.1328 - val_acc: 0.9637\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 4s 69us/step - loss: 0.1248 - acc: 0.9631 - val_loss: 0.1330 - val_acc: 0.9652\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 5s 91us/step - loss: 0.1241 - acc: 0.9638 - val_loss: 0.1309 - val_acc: 0.9652 - loss: 0.1235 -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb40a6f668>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[ES],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 27us/step\n",
      "final accuracy MLP =  0.9549\n"
     ]
    }
   ],
   "source": [
    "print('final accuracy MLP = ',model.evaluate(X_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dense_with_skip(x, dense):\n",
    "    skip = x\n",
    "    x = dense(x)\n",
    "    x = Add()([x,skip])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dense_factory(size=17):\n",
    "    return Dense(size,\n",
    "                 activation = 'relu',\n",
    "                 kernel_initializer = initializers.RandomNormal(0.0, 0.01, seed=123),\n",
    "                 bias_initializer = 'zero',\n",
    "                 \n",
    "                \n",
    "                )\n",
    "x_in = Input(shape=(pixel_count,))\n",
    "\n",
    "x = dense_factory()(x_in)\n",
    "\n",
    "num_layers_with_skip = 10\n",
    "for i in range(0,num_layers_with_skip):\n",
    "    x = dense_with_skip(x, dense_factory())\n",
    "\n",
    "# output layer\n",
    "x = Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[x_in], outputs= x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 355)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 17)           6052        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 17)           306         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 17)           0           dense_8[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 17)           306         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 17)           0           dense_9[0][0]                    \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 17)           306         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 17)           0           dense_10[0][0]                   \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 17)           306         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 17)           0           dense_11[0][0]                   \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 17)           306         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 17)           0           dense_12[0][0]                   \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 17)           306         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 17)           0           dense_13[0][0]                   \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 17)           306         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 17)           0           dense_14[0][0]                   \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 17)           306         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 17)           0           dense_15[0][0]                   \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 17)           306         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 17)           0           dense_16[0][0]                   \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 17)           306         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 17)           0           dense_17[0][0]                   \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 10)           180         add_10[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 9,292\n",
      "Trainable params: 9,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='AdaGrad',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/500\n",
      "54000/54000 [==============================] - 9s 159us/step - loss: 0.3992 - acc: 0.8806 - val_loss: 0.2234 - val_acc: 0.9355\n",
      "Epoch 2/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.2437 - acc: 0.9283 - val_loss: 0.1993 - val_acc: 0.9410\n",
      "Epoch 3/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.2124 - acc: 0.9369 - val_loss: 0.1800 - val_acc: 0.9482\n",
      "Epoch 4/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.1950 - acc: 0.9420 - val_loss: 0.1615 - val_acc: 0.9538\n",
      "Epoch 5/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1831 - acc: 0.9461 - val_loss: 0.1585 - val_acc: 0.9563\n",
      "Epoch 6/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1752 - acc: 0.9479 - val_loss: 0.1550 - val_acc: 0.9540\n",
      "Epoch 7/500\n",
      "54000/54000 [==============================] - 74s 1ms/step - loss: 0.1682 - acc: 0.9501 - val_loss: 0.1509 - val_acc: 0.9587\n",
      "Epoch 8/500\n",
      "54000/54000 [==============================] - 7s 135us/step - loss: 0.1627 - acc: 0.9518 - val_loss: 0.1440 - val_acc: 0.9603\n",
      "Epoch 9/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1574 - acc: 0.9524 - val_loss: 0.1405 - val_acc: 0.9625\n",
      "Epoch 10/500\n",
      "54000/54000 [==============================] - 7s 128us/step - loss: 0.1535 - acc: 0.9534 - val_loss: 0.1394 - val_acc: 0.9623\n",
      "Epoch 11/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1497 - acc: 0.9550 - val_loss: 0.1363 - val_acc: 0.9625\n",
      "Epoch 12/500\n",
      "54000/54000 [==============================] - 7s 123us/step - loss: 0.1464 - acc: 0.9558 - val_loss: 0.1365 - val_acc: 0.9627\n",
      "Epoch 13/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1435 - acc: 0.9570 - val_loss: 0.1347 - val_acc: 0.9638\n",
      "Epoch 14/500\n",
      "54000/54000 [==============================] - 73s 1ms/step - loss: 0.1408 - acc: 0.9575 - val_loss: 0.1331 - val_acc: 0.9635\n",
      "Epoch 15/500\n",
      "54000/54000 [==============================] - 8s 149us/step - loss: 0.1381 - acc: 0.9579 - val_loss: 0.1351 - val_acc: 0.9638\n",
      "Epoch 16/500\n",
      "54000/54000 [==============================] - 7s 137us/step - loss: 0.1361 - acc: 0.9585 - val_loss: 0.1299 - val_acc: 0.9657\n",
      "Epoch 17/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.1337 - acc: 0.9595 - val_loss: 0.1341 - val_acc: 0.9632\n",
      "Epoch 18/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1320 - acc: 0.9603 - val_loss: 0.1340 - val_acc: 0.9648\n",
      "Epoch 19/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1303 - acc: 0.9609 - val_loss: 0.1281 - val_acc: 0.9648\n",
      "Epoch 20/500\n",
      "54000/54000 [==============================] - 7s 126us/step - loss: 0.1282 - acc: 0.9606 - val_loss: 0.1282 - val_acc: 0.9648\n",
      "Epoch 21/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.1269 - acc: 0.9616 - val_loss: 0.1264 - val_acc: 0.9667\n",
      "Epoch 22/500\n",
      "54000/54000 [==============================] - 73s 1ms/step - loss: 0.1251 - acc: 0.9621 - val_loss: 0.1273 - val_acc: 0.9658\n",
      "Epoch 23/500\n",
      "54000/54000 [==============================] - 8s 151us/step - loss: 0.1238 - acc: 0.9628 - val_loss: 0.1265 - val_acc: 0.9647\n",
      "Epoch 24/500\n",
      "54000/54000 [==============================] - 7s 133us/step - loss: 0.1220 - acc: 0.9632 - val_loss: 0.1298 - val_acc: 0.9637\n",
      "Epoch 25/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1212 - acc: 0.9634 - val_loss: 0.1250 - val_acc: 0.9650\n",
      "Epoch 26/500\n",
      "54000/54000 [==============================] - 7s 123us/step - loss: 0.1201 - acc: 0.9636 - val_loss: 0.1257 - val_acc: 0.9648\n",
      "Epoch 27/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1189 - acc: 0.9641 - val_loss: 0.1253 - val_acc: 0.9645\n",
      "Epoch 28/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1178 - acc: 0.9646 - val_loss: 0.1251 - val_acc: 0.9658\n",
      "Epoch 29/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1165 - acc: 0.9651 - val_loss: 0.1249 - val_acc: 0.9650\n",
      "Epoch 30/500\n",
      "54000/54000 [==============================] - 75s 1ms/step - loss: 0.1155 - acc: 0.9654 - val_loss: 0.1266 - val_acc: 0.9647\n",
      "Epoch 31/500\n",
      "54000/54000 [==============================] - 7s 137us/step - loss: 0.1147 - acc: 0.9657 - val_loss: 0.1247 - val_acc: 0.9660\n",
      "Epoch 32/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1140 - acc: 0.9660 - val_loss: 0.1243 - val_acc: 0.9652\n",
      "Epoch 33/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1129 - acc: 0.9659 - val_loss: 0.1246 - val_acc: 0.9643\n",
      "Epoch 34/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1119 - acc: 0.9666 - val_loss: 0.1235 - val_acc: 0.9658\n",
      "Epoch 35/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.1111 - acc: 0.9664 - val_loss: 0.1255 - val_acc: 0.9647\n",
      "Epoch 36/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.1102 - acc: 0.9669 - val_loss: 0.1224 - val_acc: 0.9653\n",
      "Epoch 37/500\n",
      "54000/54000 [==============================] - 73s 1ms/step - loss: 0.1094 - acc: 0.9669 - val_loss: 0.1246 - val_acc: 0.9657\n",
      "Epoch 38/500\n",
      "54000/54000 [==============================] - 8s 149us/step - loss: 0.1086 - acc: 0.9674 - val_loss: 0.1255 - val_acc: 0.9650\n",
      "Epoch 39/500\n",
      "54000/54000 [==============================] - 7s 138us/step - loss: 0.1082 - acc: 0.9674 - val_loss: 0.1229 - val_acc: 0.9660\n",
      "Epoch 40/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.1074 - acc: 0.9679 - val_loss: 0.1223 - val_acc: 0.9657\n",
      "Epoch 41/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.1062 - acc: 0.9679 - val_loss: 0.1226 - val_acc: 0.9675\n",
      "Epoch 42/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1060 - acc: 0.9678 - val_loss: 0.1221 - val_acc: 0.9658\n",
      "Epoch 43/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1052 - acc: 0.9685 - val_loss: 0.1233 - val_acc: 0.9660\n",
      "Epoch 44/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.1048 - acc: 0.9684 - val_loss: 0.1237 - val_acc: 0.9648\n",
      "Epoch 45/500\n",
      "54000/54000 [==============================] - 73s 1ms/step - loss: 0.1040 - acc: 0.9690 - val_loss: 0.1256 - val_acc: 0.9650\n",
      "Epoch 46/500\n",
      "54000/54000 [==============================] - 8s 150us/step - loss: 0.1032 - acc: 0.9691 - val_loss: 0.1236 - val_acc: 0.9658\n",
      "Epoch 47/500\n",
      "54000/54000 [==============================] - 7s 133us/step - loss: 0.1023 - acc: 0.9694 - val_loss: 0.1292 - val_acc: 0.9640\n",
      "Epoch 48/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1022 - acc: 0.9693 - val_loss: 0.1230 - val_acc: 0.9648\n",
      "Epoch 49/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.1015 - acc: 0.9698 - val_loss: 0.1219 - val_acc: 0.9662\n",
      "Epoch 50/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.1012 - acc: 0.9694 - val_loss: 0.1240 - val_acc: 0.9648\n",
      "Epoch 51/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.1003 - acc: 0.9699 - val_loss: 0.1225 - val_acc: 0.9660\n",
      "Epoch 52/500\n",
      "54000/54000 [==============================] - 73s 1ms/step - loss: 0.1000 - acc: 0.9699 - val_loss: 0.1225 - val_acc: 0.9657\n",
      "Epoch 53/500\n",
      "54000/54000 [==============================] - 8s 151us/step - loss: 0.0995 - acc: 0.9698 - val_loss: 0.1229 - val_acc: 0.9663\n",
      "Epoch 54/500\n",
      "54000/54000 [==============================] - 8s 140us/step - loss: 0.0989 - acc: 0.9702 - val_loss: 0.1218 - val_acc: 0.9653\n",
      "Epoch 55/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.0984 - acc: 0.9705 - val_loss: 0.1227 - val_acc: 0.9655\n",
      "Epoch 56/500\n",
      "54000/54000 [==============================] - 7s 126us/step - loss: 0.0979 - acc: 0.9704 - val_loss: 0.1229 - val_acc: 0.9645\n",
      "Epoch 57/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.0975 - acc: 0.9708 - val_loss: 0.1250 - val_acc: 0.9653\n",
      "Epoch 58/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.0970 - acc: 0.9712 - val_loss: 0.1235 - val_acc: 0.9648\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.0965 - acc: 0.9710 - val_loss: 0.1255 - val_acc: 0.9635\n",
      "Epoch 60/500\n",
      "54000/54000 [==============================] - 74s 1ms/step - loss: 0.0959 - acc: 0.9713 - val_loss: 0.1247 - val_acc: 0.9642\n",
      "Epoch 61/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.0955 - acc: 0.9711 - val_loss: 0.1244 - val_acc: 0.9630\n",
      "Epoch 62/500\n",
      "54000/54000 [==============================] - 7s 139us/step - loss: 0.0953 - acc: 0.9712 - val_loss: 0.1228 - val_acc: 0.9648\n",
      "Epoch 63/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.0948 - acc: 0.9716 - val_loss: 0.1226 - val_acc: 0.9657\n",
      "Epoch 64/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.0945 - acc: 0.9716 - val_loss: 0.1239 - val_acc: 0.9645\n",
      "Epoch 65/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.0942 - acc: 0.9718 - val_loss: 0.1242 - val_acc: 0.9638\n",
      "Epoch 66/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.0938 - acc: 0.9717 - val_loss: 0.1258 - val_acc: 0.9647\n",
      "Epoch 67/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.0934 - acc: 0.9720 - val_loss: 0.1234 - val_acc: 0.9643\n",
      "Epoch 68/500\n",
      "54000/54000 [==============================] - 43s 791us/step - loss: 0.0931 - acc: 0.9719 - val_loss: 0.1228 - val_acc: 0.9652\n",
      "Epoch 69/500\n",
      "54000/54000 [==============================] - 8s 150us/step - loss: 0.0926 - acc: 0.9725 - val_loss: 0.1235 - val_acc: 0.9638\n",
      "Epoch 70/500\n",
      "54000/54000 [==============================] - 7s 130us/step - loss: 0.0922 - acc: 0.9720 - val_loss: 0.1240 - val_acc: 0.9648\n",
      "Epoch 71/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.0919 - acc: 0.9724 - val_loss: 0.1244 - val_acc: 0.9642\n",
      "Epoch 72/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.0915 - acc: 0.9726 - val_loss: 0.1241 - val_acc: 0.9650\n",
      "Epoch 73/500\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.0914 - acc: 0.9728 - val_loss: 0.1238 - val_acc: 0.9658\n",
      "Epoch 74/500\n",
      "54000/54000 [==============================] - 7s 125us/step - loss: 0.0909 - acc: 0.9723 - val_loss: 0.1252 - val_acc: 0.9643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1397e80f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[ES],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 44us/step\n",
      "final accuracy ResNet =  0.9595\n"
     ]
    }
   ],
   "source": [
    "print('final accuracy ResNet = ',model.evaluate(X_test, y_test)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
